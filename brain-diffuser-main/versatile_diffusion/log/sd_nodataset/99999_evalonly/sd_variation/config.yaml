env:
  computer:
  - Linux
  - aireps
  - 5.14.0-1051-oem
  - '#58-Ubuntu SMP Fri Aug 26 05:50:00 UTC 2022'
  - x86_64
  cuda: true
  debug: false
  dist_backend: nccl
  dist_url: tcp://127.0.0.1:11233
  experiment_id: 99999
  gpu_count: 2
  gpu_device:
  - 0
  - 1
  log_root_dir: log
  master_addr: 127.0.0.1
  master_port: 11233
  matplotlib_mode: agg
  node_rank: 0
  nodes: 1
  rnd_seed: 200
  torch_version: 1.12.1
eval:
  batch_size: 0
  batch_size_per_gpu: 0
  color_adj: true
  color_adj_keep_ratio: 0.5
  color_adj_simple: true
  conditioning:
  - assets/benz.jpg
  - assets/ghibli.jpg
  - assets/horse.png
  - assets/matisse.jpg
  - assets/penguin.png
  - assets/scream.jpg
  - assets/space.jpg
  - assets/vermeer.jpg
  - assets/boy_and_girl.jpg
  - assets/church.jpg
  - assets/firework.jpg
  - assets/house_by_lake.jpg
  - assets/night_light.jpg
  - assets/san_diego.jpg
  - assets/tiger.jpg
  - assets/train.jpg
  dataset: null
  dataset_num_workers: 0
  dataset_num_workers_per_gpu: 0
  eval_subdir: sd_variation
  fix_seed: true
  is_lite: true
  log_dir: log/sd_nodataset/99999_evalonly/sd_variation
  log_file: log/sd_nodataset/99999_evalonly/sd_variation/eval.log
  main: lib.experiments.sd_default.eval
  pretrained_pth_ema: pretrained/sd-variation-ema.pth
  replicate: 1
  sample:
    ddim_eta: 0.0
    ddim_steps: 50
    n_samples: 1
    output_dim:
    - 512
    - 512
    scale: 7.5
  save_code: true
  stage: lib.experiments.sd_default.eval_stage_variation
  strict_sd: true
model:
  args:
    beta_linear_end: 0.012
    beta_linear_start: 0.00085
    cond_stage_config:
      args: {}
      name: clip_vision_frozen_justin
      symbol: clip
      type: clip_vision_frozen_justin
    first_stage_config:
      args:
        ddconfig:
          attn_resolutions: []
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          double_z: true
          dropout: 0.0
          in_channels: 3
          num_res_blocks: 2
          out_ch: 3
          resolution: 256
          z_channels: 4
        embed_dim: 4
        lossconfig:
          target: torch.nn.Identity
        monitor: val/rec_loss
      name: sd_autoencoder
      pth: pretrained/kl-f8.pth
      type: autoencoderkl
    num_timesteps_cond: 1
    scale_factor: 0.18215
    timesteps: 1000
    unet_config:
      args:
        attention_resolutions:
        - 4
        - 2
        - 1
        channel_mult:
        - 1
        - 2
        - 4
        - 4
        context_dim: 768
        image_size: null
        in_channels: 4
        legacy: false
        model_channels: 320
        num_heads: 8
        num_res_blocks:
        - 2
        - 2
        - 2
        - 2
        out_channels: 4
        transformer_depth: 1
        use_checkpoint: true
        use_spatial_transformer: true
      name: openai_unet_sd
      type: openai_unet
    use_ema: true
  find_unused_parameters: true
  name: sd_variation
  symbol: sd
  type: sd_variation
